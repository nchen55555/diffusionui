{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHCa5Oo_xbOz",
        "outputId": "3f11eb0e-bb90-4ec9-9ce2-7f4023d7bf81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Jun 23 21:21:14 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   55C    P0    27W /  70W |   8373MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "|   1  Tesla T4            Off  | 00000000:00:05.0 Off |                    0 |\n",
            "| N/A   37C    P8     9W /  70W |      3MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: diffusers==0.17.0 in /usr/local/lib/python3.10/dist-packages (0.17.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.17.0) (2022.10.31)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers==0.17.0) (6.6.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.17.0) (0.15.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from diffusers==0.17.0) (3.12.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from diffusers==0.17.0) (2.27.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from diffusers==0.17.0) (8.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from diffusers==0.17.0) (1.22.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.2->diffusers==0.17.0) (6.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.2->diffusers==0.17.0) (23.1)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.2->diffusers==0.17.0) (4.65.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.2->diffusers==0.17.0) (4.5.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.2->diffusers==0.17.0) (2023.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers==0.17.0) (3.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.17.0) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.17.0) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.17.0) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.17.0) (3.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.30.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.10.1)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.10/dist-packages (6.1.1)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.20.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ftfy) (0.2.6)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.0+cu118)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (2.0.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate) (16.0.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->accelerate) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->accelerate) (1.3.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2022.12.7)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (8.4.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install -q streamlit\n",
        "!nvidia-smi\n",
        "!pip install diffusers==0.17.0\n",
        "!pip install transformers scipy ftfy accelerate\n",
        "!pip install requests\n",
        "!pip install pillow\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile UI/pages/1_📈_Model_A.py\n",
        "import streamlit as st\n",
        "from transformers import AutoProcessor, AutoModelForCausalLM, BlipProcessor, BlipForConditionalGeneration\n",
        "import requests\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "from diffusers import StableDiffusionControlNetPipeline\n",
        "from diffusers.utils import load_image\n",
        "\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from diffusers import StableDiffusionControlNetPipeline, ControlNetModel\n",
        "import torch\n",
        "from diffusers import UniPCMultistepScheduler\n",
        "st.set_page_config(\n",
        "    page_title=\"Realistic Vision V1.4 CUDA Blip Base\",\n",
        "    page_icon=\"📈\",\n",
        ")\n",
        "\n",
        "st.title('Realistic Vision V1.4 CUDA Blip Base')\n",
        "temp_prompt = ''\n",
        "\n",
        "def imageurl_process(url):\n",
        "    # submit image url into blip base processor\n",
        "    processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
        "    model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\").to(\"cuda\")\n",
        "    raw_image = Image.open(requests.get(url, stream=True).raw).convert('RGB')\n",
        "    # unconditioned prompt generation\n",
        "    text = \"a photography of\"\n",
        "    inputs = processor(raw_image, text, return_tensors=\"pt\").to(\"cuda\")\n",
        "    # conditioned prompt generation\n",
        "    out = model.generate(**inputs)\n",
        "    inputs = processor(raw_image, return_tensors=\"pt\").to(\"cuda\")\n",
        "    out = model.generate(**inputs)\n",
        "    temp_prompt = processor.decode(out[0], skip_special_tokens=True)\n",
        "    # generate prompt and output\n",
        "    st.info(temp_prompt)\n",
        "    return temp_prompt\n",
        "\n",
        "def prompt_process(text, url):\n",
        "  model = \"SG161222/Realistic_Vision_V1.4\"\n",
        "  controlnet = ControlNetModel.from_pretrained(\"lllyasviel/sd-controlnet-canny\", torch_dtype=torch.float16)\n",
        "  pipe = StableDiffusionControlNetPipeline.from_pretrained(\n",
        "      model, controlnet=controlnet, torch_dtype=torch.float16\n",
        "  )\n",
        "\n",
        "  pipe.scheduler = UniPCMultistepScheduler.from_config(pipe.scheduler.config)\n",
        "\n",
        "  pipe.enable_model_cpu_offload()\n",
        "\n",
        "  low_threshold = 100\n",
        "  high_threshold = 200\n",
        "\n",
        "  starter, ender = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)\n",
        "  repetitions = 20\n",
        "  timings =np.zeros((repetitions,1))\n",
        "  image = load_image(url)\n",
        "  image = np.array(image)\n",
        "  image = cv2.Canny(image, low_threshold, high_threshold)\n",
        "  image = image[:, :, None]\n",
        "  image = np.concatenate([image, image, image], axis=2)\n",
        "  canny_image = Image.fromarray(image)\n",
        "  add = \", best quality, extremely detailed\"\n",
        "  finalprompt = [text + add][:77]\n",
        "  generator = [torch.Generator(device=\"cuda\").manual_seed(2)]\n",
        "  output = pipe(\n",
        "    finalprompt,\n",
        "    canny_image,\n",
        "    negative_prompt=[\"monochrome, lowres, bad anatomy, worst quality, low quality\"],\n",
        "    generator=generator,\n",
        "    num_inference_steps=20,\n",
        "  )\n",
        "  image = output.images[0]\n",
        "  return image\n",
        "\n",
        "\n",
        "if 'stage' not in st.session_state:\n",
        "    st.session_state.stage = 0\n",
        "\n",
        "def set_stage(stage):\n",
        "    st.session_state.stage = stage\n",
        "\n",
        "first_form = st.form('image_url')\n",
        "url = first_form.text_input('Enter Image URL: ', '')\n",
        "first_form.form_submit_button('Generate Prompt', on_click=set_stage, args=(1,))\n",
        "\n",
        "if st.session_state.stage > 0:\n",
        "    temp_prompt = imageurl_process(url)\n",
        "    second_form = st.form('prompt')\n",
        "    topic_text = second_form.text_input('Enter Prompt: ')\n",
        "    second_form.form_submit_button('Generate Image', on_click=set_stage, args=(2,))\n",
        "    if st.session_state.stage > 1:\n",
        "        st.image(prompt_process(topic_text, url))\n",
        "st.button('Reset', on_click=set_stage, args=(0,))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSM8tY8t0T2f",
        "outputId": "e96c64bb-1ace-4388-f7dc-54ec085d77bc"
      },
      "execution_count": 239,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting UI/pages/1_📈_Model_A.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile UI/pages/2_🌍_Model_B.py\n",
        "\n",
        "import streamlit as st\n",
        "from transformers import AutoProcessor, AutoModelForCausalLM, BlipProcessor, BlipForConditionalGeneration\n",
        "import requests\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "from diffusers import StableDiffusionControlNetPipeline\n",
        "from diffusers.utils import load_image\n",
        "\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from diffusers import StableDiffusionControlNetPipeline, ControlNetModel\n",
        "import torch\n",
        "from diffusers import UniPCMultistepScheduler\n",
        "\n",
        "st.set_page_config(\n",
        "    page_title=\"Realistic Vision V1.4 CUDA Git Large Coco\",\n",
        "    page_icon=\"🌍\",\n",
        ")\n",
        "\n",
        "st.title('Realistic Vision V1.4 CUDA Git Large Coco')\n",
        "temp_prompt = ''\n",
        "\n",
        "def imageurl_process(url):\n",
        "    processor = AutoProcessor.from_pretrained(\"microsoft/git-base-coco\")\n",
        "    model = AutoModelForCausalLM.from_pretrained(\"microsoft/git-base-coco\")\n",
        "    image = Image.open(requests.get(url, stream=True).raw)\n",
        "    pixel_values = processor(images=image, return_tensors=\"pt\").pixel_values\n",
        "    generated_ids = model.generate(pixel_values=pixel_values, max_length=50)\n",
        "    temp_prompt = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "    st.info(temp_prompt)\n",
        "    return temp_prompt\n",
        "\n",
        "def prompt_process(text, url):\n",
        "  model = \"SG161222/Realistic_Vision_V1.4\"\n",
        "  controlnet = ControlNetModel.from_pretrained(\"lllyasviel/sd-controlnet-canny\", torch_dtype=torch.float16)\n",
        "  pipe = StableDiffusionControlNetPipeline.from_pretrained(\n",
        "      model, controlnet=controlnet, torch_dtype=torch.float16\n",
        "  )\n",
        "\n",
        "  pipe.scheduler = UniPCMultistepScheduler.from_config(pipe.scheduler.config)\n",
        "\n",
        "  pipe.enable_model_cpu_offload()\n",
        "\n",
        "  low_threshold = 100\n",
        "  high_threshold = 200\n",
        "\n",
        "  starter, ender = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)\n",
        "  repetitions = 20\n",
        "  timings =np.zeros((repetitions,1))\n",
        "  image = load_image(url)\n",
        "  image = np.array(image)\n",
        "  image = cv2.Canny(image, low_threshold, high_threshold)\n",
        "  image = image[:, :, None]\n",
        "  image = np.concatenate([image, image, image], axis=2)\n",
        "  canny_image = Image.fromarray(image)\n",
        "  add = \", best quality, extremely detailed\"\n",
        "  finalprompt = [text + add][:77]\n",
        "  generator = [torch.Generator(device=\"cuda\").manual_seed(2)]\n",
        "  output = pipe(\n",
        "    finalprompt,\n",
        "    canny_image,\n",
        "    negative_prompt=[\"monochrome, lowres, bad anatomy, worst quality, low quality\"],\n",
        "    generator=generator,\n",
        "    num_inference_steps=20,\n",
        "  )\n",
        "  image = output.images[0]\n",
        "  return st.image(image)\n",
        "\n",
        "if 'stage' not in st.session_state:\n",
        "    st.session_state.stage = 0\n",
        "\n",
        "def set_stage(stage):\n",
        "    st.session_state.stage = stage\n",
        "\n",
        "first_form = st.form('image_url')\n",
        "url = first_form.text_input('Enter Image URL: ', '')\n",
        "first_form.form_submit_button('Generate Prompt', on_click=set_stage, args=(1,))\n",
        "\n",
        "if st.session_state.stage > 0:\n",
        "    temp_prompt = imageurl_process(url)\n",
        "    second_form = st.form('prompt')\n",
        "    topic_text = second_form.text_input('Enter Prompt: ')\n",
        "    second_form.form_submit_button('Generate Image', on_click=set_stage, args=(2,))\n",
        "    if st.session_state.stage > 1:\n",
        "        st.image(prompt_process(topic_text, url))\n",
        "st.button('Reset', on_click=set_stage, args=(0,))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IqG6vWQQFnoN",
        "outputId": "85c70adb-e404-4be9-b8b2-795a97094546"
      },
      "execution_count": 238,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting UI/pages/2_🌍_Model_B.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile UI/pages/3_📊_Model_C.py\n",
        "\n",
        "import streamlit as st\n",
        "from transformers import AutoProcessor, AutoModelForCausalLM, BlipProcessor, BlipForConditionalGeneration\n",
        "import requests\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "from diffusers import StableDiffusionControlNetPipeline\n",
        "from diffusers.utils import load_image\n",
        "\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from diffusers import StableDiffusionControlNetPipeline, ControlNetModel\n",
        "import torch\n",
        "from diffusers import UniPCMultistepScheduler\n",
        "\n",
        "st.set_page_config(\n",
        "    page_title=\"Photoreal 2.0 CUDA Git Large Coco\",\n",
        "    page_icon=\"📊\",\n",
        ")\n",
        "\n",
        "st.title('Photoreal 2.0 CUDA Git Large Coco')\n",
        "temp_prompt = ''\n",
        "\n",
        "def imageurl_process(url):\n",
        "    processor = AutoProcessor.from_pretrained(\"microsoft/git-base-coco\")\n",
        "    model = AutoModelForCausalLM.from_pretrained(\"microsoft/git-base-coco\")\n",
        "    image = Image.open(requests.get(url, stream=True).raw)\n",
        "    pixel_values = processor(images=image, return_tensors=\"pt\").pixel_values\n",
        "    generated_ids = model.generate(pixel_values=pixel_values, max_length=50)\n",
        "    temp_prompt = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "    st.info(temp_prompt)\n",
        "    return temp_prompt\n",
        "\n",
        "def prompt_process(text, url):\n",
        "  model = \"dreamlike-art/dreamlike-photoreal-2.0\"\n",
        "  controlnet = ControlNetModel.from_pretrained(\"lllyasviel/sd-controlnet-canny\", torch_dtype=torch.float16)\n",
        "  pipe = StableDiffusionControlNetPipeline.from_pretrained(\n",
        "      model, controlnet=controlnet, torch_dtype=torch.float16\n",
        "  )\n",
        "\n",
        "  pipe.scheduler = UniPCMultistepScheduler.from_config(pipe.scheduler.config)\n",
        "\n",
        "  pipe.enable_model_cpu_offload()\n",
        "\n",
        "  low_threshold = 100\n",
        "  high_threshold = 200\n",
        "\n",
        "  starter, ender = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)\n",
        "  repetitions = 20\n",
        "  timings =np.zeros((repetitions,1))\n",
        "  image = load_image(url)\n",
        "  image = np.array(image)\n",
        "  image = cv2.Canny(image, low_threshold, high_threshold)\n",
        "  image = image[:, :, None]\n",
        "  image = np.concatenate([image, image, image], axis=2)\n",
        "  canny_image = Image.fromarray(image)\n",
        "  add = \", best quality, extremely detailed\"\n",
        "  finalprompt = [text + add][:77]\n",
        "  generator = [torch.Generator(device=\"cuda\").manual_seed(2)]\n",
        "  output = pipe(\n",
        "    finalprompt,\n",
        "    canny_image,\n",
        "    negative_prompt=[\"monochrome, lowres, bad anatomy, worst quality, low quality\"],\n",
        "    generator=generator,\n",
        "    num_inference_steps=20,\n",
        "  )\n",
        "  image = output.images[0]\n",
        "  return st.image(image)\n",
        "\n",
        "if 'stage' not in st.session_state:\n",
        "    st.session_state.stage = 0\n",
        "\n",
        "def set_stage(stage):\n",
        "    st.session_state.stage = stage\n",
        "\n",
        "first_form = st.form('image_url')\n",
        "url = first_form.text_input('Enter Image URL: ', '')\n",
        "first_form.form_submit_button('Generate Prompt', on_click=set_stage, args=(1,))\n",
        "\n",
        "if st.session_state.stage > 0:\n",
        "    temp_prompt = imageurl_process(url)\n",
        "    second_form = st.form('prompt')\n",
        "    topic_text = second_form.text_input('Enter Prompt: ')\n",
        "    second_form.form_submit_button('Generate Image', on_click=set_stage, args=(2,))\n",
        "    if st.session_state.stage > 1:\n",
        "        st.image(prompt_process(topic_text, url))\n",
        "st.button('Reset', on_click=set_stage, args=(0,))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SfDKlOJEH6jc",
        "outputId": "a610600d-aecf-49a8-fc45-086eb44d210f"
      },
      "execution_count": 237,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting UI/pages/3_📊_Model_C.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile UI/Home.py\n",
        "\n",
        "import streamlit as st\n",
        "\n",
        "st.write(\"# Welcome to a Live Demo of the Experimental Generative AI Models for Tile Generation! 👋\")\n",
        "\n",
        "st.sidebar.success(\"Select a model to run above.\")\n",
        "\n",
        "st.markdown(\n",
        "    \"\"\"\n",
        "    **👈 Select a model** to experiment with recreating some images!\n",
        "    ### Steps\n",
        "    - Input an image url into the first form to generate a prompt\n",
        "    - Customize the prompt or directly copy and paste it into the second form for image regeneration\n",
        "    - For more information about the different models, check out this [presentation](https://drive.google.com/file/d/1cGuGW_FV0nmErdlhsaOx9vsiANP-3bf0/view?usp=drive_link)\n",
        "    ### Overview\n",
        "    - Model A is Realistic Vision V1.4 CUDA Blip Base (the best overall model)\n",
        "    - Model B is Realistic Vision V1.4 CUDA Git Large Coco (the best disregarding NSFW scores)\n",
        "    - Model C is Photoreal 2.0 CUDA Git Large Coco (the best disregarding any quality assesments)\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "st.markdown(\":green[Created By Nicole Chen]\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wKck401GKcb",
        "outputId": "1365537f-3914-4385-a220-230c989788ae"
      },
      "execution_count": 247,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting UI/Home.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!npm install localtunnel\n",
        "!streamlit run UI/Home.py &>/content/logs.txt &\n",
        "!npx localtunnel --port 8501 & curl ipv4.icanhazip.com"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYWOMZae0ZAd",
        "outputId": "3e21548b-eed1-4f43-82a9-c0c0d8d43f3f"
      },
      "execution_count": 248,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K\u001b[?25h\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35msaveError\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35menoent\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No description\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No repository field.\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No README data\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No license field.\n",
            "\u001b[0m\n",
            "+ localtunnel@2.0.2\n",
            "updated 1 package and audited 36 packages in 0.303s\n",
            "\n",
            "3 packages are looking for funding\n",
            "  run `npm fund` for details\n",
            "\n",
            "found \u001b[92m0\u001b[0m vulnerabilities\n",
            "\n",
            "34.168.25.84\n",
            "\u001b[K\u001b[?25hnpx: installed 22 in 1.232s\n",
            "your url is: https://cute-mugs-warn.loca.lt\n"
          ]
        }
      ]
    }
  ]
}